{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P4J0wc1NkWj"
      },
      "source": [
        "# Project: Movie Classification\n",
        "## Introduction\n",
        "Welcome to the final project of Foundations of Data Science! In this Capstone Project, you will develop a classifier that can determine whether a movie is a comedy or a thriller based solely on the frequency of specific words in the movie's screenplay. This project will not only enhance your understanding of machine learning techniques but also reinforce the data science concepts you've learned throughout the course.\n",
        "\n",
        "## Objectives\n",
        "By the end of this project, you will be able to:\n",
        "\n",
        "1. Build and understand the workings of a k-nearest-neighbors (KNN) classifier.\n",
        "2. Test and evaluate the performance of your classifier on a dataset.\n",
        "3. Create a presentation to communicate your journey through the data science life cycle to realize your final classifier\n",
        "\n",
        "This project also offers a chance to review other essential data exploration and inference tools that you have learned in this course.\n",
        "\n",
        "## Logistics\n",
        "### Deadline\n",
        "- **Latest Submission Date:** The project must be completed by 11:59 pm on Tuesday, May 14th. Students' presentations of their classifiers will be on Wednesday May15th during class.\n",
        "\n",
        "\n",
        "### Support\n",
        "- **Class Time:** Take advantage of class time for discussions with classmates or to seek clarification on project requirements.\n",
        "- **Personal Support:** If you're feeling overwhelmed or stuck, reach out for a one-on-one discussion. Our goal is to make this learning experience both challenging and exciting.\n",
        "\n",
        "### Testing\n",
        "- **Preliminary Tests:** Passing these tests does not guarantee correctness; they typically check only the structure of your data.\n",
        "\n",
        "- **Final Evaluation:** Additional tests will verify the accuracy of your submissions for grading. Review and verify your work carefully, then prepare a presentation that communicates the relevant insights discovered throughout your steps through the data science life cycle to realize your final classifier to the class. You may assume a persona for the class and tailor your presentation to that persona. For example, you could assume that your audience is the executive board of Netflix and you would like them to adopt your movie classifier. Be creative - the goal here is to think about how you communicate your results and the likely value and implication of your analysis to a target audience. (*Hint: You should probably think about the target audience before you begin your analysis - extra credit for creativity*)\n",
        "\n",
        "### Advice\n",
        "- Incremental Development: Break down complex tasks into manageable steps. Use separate lines for each step, name each result distinctly, and verify outcomes at each stage.\n",
        "\n",
        "\n",
        "### Getting Started\n",
        "We have included the workbook with the necessary libraries, make sure to load the necessary libraries:\n",
        "\n",
        "- `datascience`\n",
        "- `numpy`\n",
        "- `plots`\n",
        "\n",
        "\n",
        "We have also provided some \"helper functions\":\n",
        "- plot_with_two_features\n",
        "- fast_distances\n",
        "\n",
        "Prepare your development environment by copying this Notebook and naming it according to the naming convention we used during term. You must upload it into your shared google drive before the deadline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IGjpRF7BSxx"
      },
      "outputs": [],
      "source": [
        "# Run this cell to set up the notebook, but please don't change it.\n",
        "import numpy as np\n",
        "import math\n",
        "from datascience import *\n",
        "\n",
        "# These lines set up the plotting functionality and formatting.\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plots\n",
        "plots.style.use('fivethirtyeight')\n",
        "import warnings\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SubtyWQBBSxy"
      },
      "source": [
        "# 1. The Dataset\n",
        "\n",
        "In this project, we are exploring movie screenplays. We'll be trying to predict each movie's genre from the text of its screenplay. In particular, we have compiled a list of 5,000 words that occur in conversations between movie characters. For each movie, our dataset tells us the frequency with which each of these words occurs in certain conversations in its screenplay. All words have been converted to lowercase.\n",
        "\n",
        "Run the cell below to read the `movies` table. **It may take up to a minute to load.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "JLvKQLWDBSxy",
        "outputId": "1e7d20a0-8dcc-4656-98d8-19b9cc50b40c"
      },
      "outputs": [],
      "source": [
        "movies = Table.read_table('movies.csv')\n",
        "movies.where(\"Title\", \"wild wild west\").select(0, 1, 2, 3, 4, 14, 49, 1042, 4004)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlfaoQ7HBSxz"
      },
      "source": [
        "The above cell prints a few columns of the row for the comedy movie *Wild Wild West*.  The movie contains 3446 words. The word \"it\" appears 74 times, as it makes up  $\\frac{74}{3446} \\approx 0.021364$ of the words in the movie. The word \"england\" doesn't appear at all.\n",
        "This numerical representation of a body of text, one that describes only the frequencies of individual words, is called a bag-of-words representation. A lot of information is discarded in this representation: the order of the words, the context of each word, who said what, the cast of characters and actors, etc. However, a bag-of-words representation is often used for machine learning applications as a reasonable starting point, because a great deal of information is also retained and expressed in a convenient and compact format. In this project, we will investigate whether this representation is sufficient to build an accurate genre classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK35JApuBSx0"
      },
      "source": [
        "All movie titles are unique. The `row_for_title` function provides fast access to the one row for each title.\n",
        "\n",
        "*Note: All movies in our dataset have their titles lower-cased.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_nn6jFZBSx0"
      },
      "outputs": [],
      "source": [
        "title_index = movies.index_by('Title')\n",
        "def row_for_title(title):\n",
        "    \"\"\"Return the row for a title, similar to the following expression (but faster)\n",
        "\n",
        "    movies.where('Title', title).row(0)\n",
        "    \"\"\"\n",
        "    return title_index.get(title)[0]\n",
        "\n",
        "row_for_title('the terminator')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iUTKoMDBSx1"
      },
      "source": [
        "For example, the fastest way to find the frequency of \"none\" in the movie *The Terminator* is to access the `'none'` item from its row. Check the original table to see if this worked for you!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4Ze-IGnBSx1"
      },
      "outputs": [],
      "source": [
        "row_for_title('the terminator').item('none')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-dDHUeMBSx3"
      },
      "source": [
        "The dataset was extracted from [a dataset from Cornell University](http://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html). After transforming the dataset (e.g., converting the words to lowercase, removing the naughty words, and converting the counts to frequencies), we created this new dataset containing the frequency of 5000 common words in each movie. Removing the columns:\"Title\", \"Year\", \"Rating\", \"Genre\", and \"# Words\" we see the 5000 words are associated with each movie and the number of movies.\n",
        "Run the code below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "pQvO7C8pBSx3",
        "outputId": "ed937ea4-1c0c-48f4-f384-0b76fc310f4f"
      },
      "outputs": [],
      "source": [
        "print('Words with frequencies:', movies.drop(np.arange(5)).num_columns)\n",
        "print('Movies with genres:', movies.num_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Si6ayLnqBSx1"
      },
      "source": [
        "#### Question 1.0\n",
        "Set `expected_row_sum` to the number that you __expect__ will result from summing all proportions in each row, excluding the first five columns.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: q1_0\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opCzn3OiBSx2"
      },
      "outputs": [],
      "source": [
        "# Set row_sum to a number that's the (approximate) sum of each row of word proportions.\n",
        "expected_row_sum = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNRKs5XoBSx3"
      },
      "source": [
        "## 1.1. Word Stemming\n",
        "The columns other than \"Title\", \"Year\", \"Rating\", \"Genre\", and \"# Words\" in the `movies` table are all words that appear in some of the movies in our dataset.  These words have been *stemmed*, or abbreviated heuristically, in an attempt to make different [inflected](https://en.wikipedia.org/wiki/Inflection) forms of the same base word into the same string.  For example, the column \"manag\" is the sum of proportions of the words \"manage\", \"manager\", \"managed\", and \"managerial\" (and perhaps others) in each movie. This is a common technique used in machine learning and natural language processing.\n",
        "\n",
        "Stemming makes it a little tricky to search for the words you want to use, so we have provided another table that will let you see examples of unstemmed versions of each stemmed word.  Run the code below to load it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "HX8wqFCFBSx4",
        "outputId": "1abc0779-fe11-4994-e261-1509049973cd",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Just run this cell.\n",
        "vocab_mapping = Table.read_table('stem.csv')\n",
        "stemmed = np.take(movies.labels, np.arange(3, len(movies.labels)))\n",
        "vocab_table = Table().with_column('Stem', stemmed).join('Stem', vocab_mapping)\n",
        "vocab_table.take(np.arange(1100, 1110))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "RlP6skw-BSx4"
      },
      "source": [
        "#### Question 1.1.1\n",
        "Assign `stemmed_message` to the stemmed version of the word \"vegetables\".\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: q1_1_1\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOjGtVR4BSx4"
      },
      "outputs": [],
      "source": [
        "stemmed_message = ...\n",
        "stemmed_message"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "c9V89vOxBSx5"
      },
      "source": [
        "#### Question 1.1.2\n",
        "What stem in the dataset has the most words that are shortened to it? Assign `most_stem` to that stem.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: q1_1_2\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG2T7WTqBSx5"
      },
      "outputs": [],
      "source": [
        "most_stem = ...\n",
        "most_stem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "d_lEYdg2BSx6"
      },
      "source": [
        "#### Question 1.1.3\n",
        "What is the longest word in the dataset whose stem wasn't shortened? Assign that to `longest_uncut`. Break ties alphabetically from Z to A (so if your options are \"albatross\" or \"batman\", you should pick \"batman\").\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: q1_1_3\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "for_assignment_type": "student",
        "id": "otROJ15hBSx6"
      },
      "outputs": [],
      "source": [
        "# In our solution, we found it useful to first add columns with\n",
        "# the length of the word and the length of the stem,\n",
        "# and then to add a column with the difference between those lengths.\n",
        "# What will the difference be if the word is not shortened?\n",
        "\n",
        "tbl_with_lens = ...\n",
        "tbl_with_dif = ...\n",
        "\n",
        "\n",
        "longest_uncut = ...\n",
        "longest_uncut"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rmiCGo0L0yN"
      },
      "source": [
        "## 2. The Data Science Life Cycle\n",
        "\n",
        "\n",
        "The Data Science Life Cycle is a framework comprising interconnected steps designed to systematically derive insights from data. Each step builds upon the previous one, ensuring a comprehensive approach to solving data-driven problems. In this project, the focus is on building a classifier to predict movie genres based on screenplay word frequencies. Below are the detailed steps of the Data Science Life Cycle as applied to this project:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Understanding the Problem\n",
        "The first step in the Data Science Life Cycle is to understand the problem at hand. For this project, our goal is to develop a classifier that can predict the genre of a movie—specifically, distinguishing between comedies and thrillers—based on the frequency of certain words in the movie’s screenplay. This problem statement guides the subsequent steps in our analysis and modeling.\n",
        "\n",
        "### Data Collection and Preparation\n",
        "We begin by examining the \"movies\" table, which includes frequencies of 5,000 stemmed words across various movies, along with metadata such as the movie title, year, rating, genre, and total word count. Ensuring that our data is clean and appropriately formatted is crucial for effective analysis.\n",
        "\n",
        "### Data Exploration & Inferential Analysis (Hypothesis formulation & Testing)\n",
        "This stage involves getting familiar with the data through various exploratory analysis techniques. Look at the distribution of genres, the range of word counts, how genres might correlate with certain words, and other patterns that could inform the development of your classifier. Visualization and summary statistics are key tools for exploration.\n",
        "\n",
        "The patterns you observed in your data may lead to formulating and testing some interesting hypothesis. For example, you may feel that there are more comedies typically have higher ratings than thrillers. In this case you would form\n",
        "\n",
        "### Model Building and Evaluation\n",
        "Using the insights gained from the exploration stage, you'll build a k-nearest-neighbors (KNN) classifier. This involves selecting features, choosing a distance metric, and deciding on the number of neighbors. You will then train your model on a subset of the data and test its performance on unseen data to evaluate its effectiveness.\n",
        "### Communication of Results\n",
        "The final step involves synthesizing your findings and the methodology into a coherent presentation aimed at stakeholders interested in your project. This presentation should cover the problem statement, your analytical approach, key findings, model performance, and potential implications of your results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqPg42H_DMzK"
      },
      "source": [
        "# 2.1 Exploring your data\n",
        "\n",
        "Begin by exploring your dataset to better understand its characteristics and prepare for the analytical tasks ahead. Given the goal of developing a classifier to predict a movie's genre from its screenplay, it's important to examine the data from multiple perspectives. Remember that visualization is key here - employ visual tools to help uncover patterns in the data. Consider using histograms for ratings distributions by genre, scatter plots to visualize relationships between different variables, etc.\n",
        "\n",
        "Here are some steps and considerations to guide your exploration:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUxZ46sxJALj"
      },
      "source": [
        "\n",
        "- 2.1.1 Understand the Dataset Structure: Familiarize yourself with the structure of the \"movies\" table. Identify the total number of entries, the types of data columns available (e.g., numeric for word frequencies, categorical for genres), and any missing values or anomalies in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcDVwkPwEAn5"
      },
      "outputs": [],
      "source": [
        "### Begin your work here. Add as many code or text cells as you deem necessary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvcsC73SJU9P"
      },
      "source": [
        "\n",
        "- 2.1.2 Statistical Summaries: Generate summary statistics for the numeric columns such as '# Words' and the frequencies of some key stemmed words. This will give you insights into the central tendency and variability of your data, which are crucial for later stages of the project.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDDRPJLJb_yq"
      },
      "outputs": [],
      "source": [
        "### Begin your work here. Add as many code or text cells as you deem necessary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uelFKHhaJwT1"
      },
      "source": [
        "- 2.1.3 Genre Distribution: Analyze the distribution of movie genres within your dataset. Understanding how genres are represented can help in assessing whether the data is balanced or if there are biases that might affect model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ichjiqQAb_tO"
      },
      "outputs": [],
      "source": [
        "### Begin your work here. Add as many code or text cells as you deem necessary.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXddmwRNKHiW"
      },
      "source": [
        "- Document Insights so far: As you explore, document your findings and any insights that could influence your approach to building the classifier. This documentation will be useful for the subsequent phases of the project.-\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_nT79veLRFZ"
      },
      "source": [
        "### Exploration Insights So Far:\n",
        "\n",
        "... \\\n",
        "... \\\n",
        "..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf_ByexTNy0n"
      },
      "source": [
        "The remainder of this notebook presents specific questions and notes essential to guiding your analysis and fulfilling the core requirements of the project. Beyond these, however, you’re encouraged to be creative in your analysis approach. Dive into trends, formulate your own additional hypotheses, and perhaps uncover unexpected insights.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vzc8spQE05d"
      },
      "source": [
        "## 2.2 Inferential Analysis:\n",
        "\n",
        "Assuming a 5% p-value cut-off, we are going to test different claims such as whether average ratings of comedies are different from average ratings of thrillers, whether proportion of comedies and thrillers are different between decades, etc.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqvdfBffjGXG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hweum7VFSaz"
      },
      "source": [
        "- 2.2.1 Do longer movies receive have higher ratings on average than shorter movies? A longer movie is one in which the word count in the movie summary exceeds the average word count recorded in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDUuZm0iOFxf"
      },
      "source": [
        "Hypothesis:\n",
        "\n",
        "  - **Null Hypothesis (Ho):** ...\n",
        "\n",
        "  - **Alternative Hypothesis (Ha):** ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0jRjC_qQgap"
      },
      "outputs": [],
      "source": [
        "### Begin your work here. Add as many code or text cells as you deem necessary.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5-_Z8lcORFX"
      },
      "source": [
        "- 2.2.2 Now let's investigate the claim that there is a significant difference in the proportion of `comedy` and `thriller` movie genres released before and after the year `2000`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYH3tCCpORIx"
      },
      "source": [
        "Hypothesis:\n",
        "  - **Null Hypothesis (Ho):** ...\n",
        "\n",
        "  - **Alternative Hypothesis (Ha):** ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXi5xVDeOtH9"
      },
      "outputs": [],
      "source": [
        "### Begin your work here. Add as many code or text cells as you deem necessary.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiyGlY271NO-"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5U7y3UABSx6"
      },
      "source": [
        "## 2.3  Exploring Relationship between words in proportions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTu57dAgBSx7"
      },
      "source": [
        "Let's look at the relationship between words in proportions.\n",
        "\n",
        "The first association we'll investigate is the association between the proportion of words that are \"outer\" and the proportion of words that are \"space\".\n",
        "\n",
        "As usual, we'll investigate our data visually before performing any numerical analysis.\n",
        "\n",
        "Run the cell below to plot a scatter diagram of space proportions vs outer proportions and to create the `outer_space` table."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk3lu7Q1BSx7",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Just run this cell!\n",
        "outer_space = movies.select(\"outer\", \"space\")\n",
        "outer_space.scatter(\"outer\", \"space\")\n",
        "plots.axis([-0.001, 0.0025, -0.001, 0.005]);\n",
        "plots.xticks(rotation=45);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "loLzVdjiBSx8"
      },
      "source": [
        "#### Question 2.3.1\n",
        "Looking at that chart it is difficult to see if there is an association. Determine if there is a true (non-random) association between proportion of words that are \"outer\" and the proportion of words that are \"space\" for every movie in the dataset.\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: q1_2_1\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WPtivNHBSx8"
      },
      "outputs": [],
      "source": [
        "### Begin your work here. Add as many code or text cells as you deem necessary.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "fPp6iYIkBSx9"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "#### Question 2.3.2\n",
        "Choose two *different* words in the dataset with a correlation higher than 0.2 or smaller than -0.2 that are not *outer* and *space* and plot a scatter plot with a line of best fit for them. The code to plot the scatter plot and line of best fit is given for you, you just need to calculate the correct values to `r`, `slope` and `intercept`.\n",
        "\n",
        "*Hint: It's easier to think of words with a positive correlation, i.e. words that are often mentioned together*.\n",
        "\n",
        "*Hint 2: Try to think of common phrases or idioms*.\n",
        "\n",
        "\n",
        "<!--\n",
        "BEGIN QUESTION\n",
        "name: q1_2_2\n",
        "manual: true\n",
        "image: true\n",
        "-->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "export_pdf": true,
        "id": "TydcSHAyBSx-"
      },
      "outputs": [],
      "source": [
        "### Begin your work here. Add as many code or text cells as you deem necessary.\n",
        "word_x = ...\n",
        "word_y = ...\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "r = ...\n",
        "slope = ...\n",
        "intercept = ...\n",
        "\n",
        "# DON'T CHANGE THESE LINES OF CODE\n",
        "movies.scatter(word_x, word_y)\n",
        "max_x = max(movies.column(word_x))\n",
        "plots.title(f\"Correlation: {r}, magnitude greater than .2: {abs(r) >= 0.2}\")\n",
        "plots.plot([0, max_x * 1.3], [intercept, intercept + slope * (max_x*1.3)], color='gold');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsVl-vWvU83J"
      },
      "source": [
        "- Can you confirm that this relationship is not due to random chance, given a p-value cut-off of 0.05?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nx_rtGJ80AB8"
      },
      "outputs": [],
      "source": [
        "### Begin your work here. Add as many code or text cells as you deem necessary.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZnOBTzDoBRC"
      },
      "source": [
        "Hopefully the exercise above gives you a hint of how you might determine  candidate features for your classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCjAv0T6BSx_"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "\n",
        "\n",
        "## 3. Building a classifier\n",
        "Now it is time to use the `movies` dataset for the purposes of:\n",
        "\n",
        "1.  *training* movie genre classifiers.\n",
        "2.  *testing* the performance of our classifiers.\n",
        "\n",
        "Hence, we need two different datasets: *training* and *test*.\n",
        "\n",
        "The purpose of a classifier is to classify unseen data that is similar to the training data. Therefore, it is important to ensure that there are no movies that appear in both sets. The dataset has already been permuted randomly, so it's easy to split.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PcV7PGHnrOl"
      },
      "source": [
        "### 3.1 Initial Set-up\n",
        "\n",
        "3.1.1 Create a train data, `train_movies` that is 85% of `movies` and a test set, `test_movies` that is 15% of the data. Then use a bar chart to display the proportion of Comedy and Thriller in each dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCSKvZtIBSx_"
      },
      "outputs": [],
      "source": [
        "### Begin your work here. Add as many code or text cells as you deem necessary.\n",
        "\n",
        "\n",
        "\n",
        "train_movies = ...\n",
        "test_movies = ...\n",
        "\n",
        "print(\"Training: \",   train_movies.num_rows, \";\",\n",
        "      \"Test: \",       test_movies.num_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a9lOX-Dx-ED"
      },
      "source": [
        "### 3.2 Initial Classifier Development\n",
        "3.2.1. Start by building a few (at least two) different simple classifiers using only two or three features and k=1. This will help establish a baseline for your classifier's performance.\n",
        "\n",
        "\n",
        "*Hint: It is advisable to develop several helper functions, especially one to encapsulate the classification process, which may improve the reusability and readability of your code, aiding in systematic experimentation and testing. Also you've done some work prior to this part of the project to ensure you are able to justify the variables you selected in your classifier(s).*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQcnXWs7x9oL"
      },
      "outputs": [],
      "source": [
        "### Begin your work here. Add as many code or text cells as you deem necessary.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7JLrGZKgkaT"
      },
      "source": [
        "The function below creates a plot to display two features (e.g \"water\" and \"feel\") of a test movie and some training movies. As you can see in the result, *Monty Python and the Holy Grail* is more similar to \"Clerks.\" than to the *The Avengers* based on these features, which is makes sense as both movies are comedy movies, while *The Avengers* is a thriller.\n",
        "\n",
        "Feel free to adapt this for your use as necessary!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "55J4GYrTBSyB"
      },
      "outputs": [],
      "source": [
        "# Just run this cell.\n",
        "def plot_with_two_features(test_movie, training_movies, x_feature, y_feature):\n",
        "    \"\"\"Plot a test movie and training movies using two features.\"\"\"\n",
        "    test_row = row_for_title(test_movie)\n",
        "    distances = Table().with_columns(\n",
        "            x_feature, [test_row.item(x_feature)],\n",
        "            y_feature, [test_row.item(y_feature)],\n",
        "            'Color',   ['unknown'],\n",
        "            'Title',   [test_movie]\n",
        "        )\n",
        "    for movie in training_movies:\n",
        "        row = row_for_title(movie)\n",
        "        distances.append([row.item(x_feature), row.item(y_feature), row.item('Genre'), movie])\n",
        "    distances.scatter(x_feature, y_feature, group='Color', labels='Title', s=30)\n",
        "\n",
        "training = [\"clerks.\", \"the avengers\"]\n",
        "plot_with_two_features(\"monty python and the holy grail\", training, \"water\", \"feel\")\n",
        "plots.axis([-0.001, 0.0011, -0.004, 0.008]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eaj-9NBR06qp"
      },
      "source": [
        "### 3.3 Classifier Evaluation\n",
        "3.3.1 Classify \"Monty Python and the Holy Grail\" and \"The Avengers\" using the five nearest neighbors in the different simple classifers you created above. Analyze the similarities and differences of their nearest neighbors.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvKsCnCZ1Nq7"
      },
      "outputs": [],
      "source": [
        "### Begin your work here. Add as many code or text cells as you deem necessary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHNLbSZN9UR7"
      },
      "source": [
        "3.3.2 If you modified one of your models to only use the features \"water\" and \"feel\", what are the names and genres of the 5 movies in the training set closest to Monty Python and the Holy Grail?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzjrDFqu9iRu"
      },
      "outputs": [],
      "source": [
        "### Begin your work here. Add as many code or text cells as you deem necessary.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zntxuDaI3yph"
      },
      "source": [
        "### 3.4 Optimizing Features\n",
        "Using too little or all of the features in a classifer has some downsides. One clear downside is computational -- computing Euclidean distances just takes a long time when we have lots of features.\n",
        "\n",
        "So we're going to select just a few no more than 20. We'd like to choose features that are very discriminative. That is, features which lead us to correctly classify as much of the test set as possible. This process of choosing features that will make a classifier work well is sometimes called feature selection, or, more broadly, feature engineering. Some things to consider as you select your features:\n",
        "\n",
        "1. words common in both comedy and thriller movies\n",
        "2. words uncommon in comedy movies and common in thriller movies\n",
        "3. words common in comedy movies and uncommon in thriller movies\n",
        "4. words uncommon in both comedy and thriller movies\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iohceEqg13b"
      },
      "source": [
        "To make calculating distances computationally faster, we have provided a function, `fast_distances`, to do this for you.  Read its documentation to make sure you understand what it does.  (Feel free to adapt and employ this function.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4BMOfSpg1BE"
      },
      "outputs": [],
      "source": [
        "# Just run this cell to define fast_distances.\n",
        "\n",
        "def fast_distances(test_row, train_table):\n",
        "    \"\"\"Return an array of the distances between test_row and each row in train_rows.\n",
        "\n",
        "    Takes 2 arguments:\n",
        "      test_row: A row of a table containing features of one\n",
        "        test movie (e.g., test_my_features.row(0)).\n",
        "      train_table: A table of features (for example, the whole\n",
        "        table train_my_features).\"\"\"\n",
        "    assert train_table.num_columns < 50, \"Make sure you're not using all the features of the movies table.\"\n",
        "    counts_matrix = np.asmatrix(train_table.columns).transpose()\n",
        "    diff = np.tile(np.array(list(test_row)), [counts_matrix.shape[0], 1]) - counts_matrix\n",
        "    np.random.seed(0) # For tie breaking purposes\n",
        "    distances = np.squeeze(np.asarray(np.sqrt(np.square(diff).sum(1))))\n",
        "    eps = np.random.uniform(size=distances.shape)*1e-10 #Noise for tie break\n",
        "    distances = distances + eps\n",
        "    return distances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT1y0mTAHAhQ"
      },
      "source": [
        "3.4.1 Engage in feature engineering and selection to refine your classifier.\n",
        "- Build three models of varying complexity:\n",
        "  - Small model: Use a minimal set of features ( less than 5).\n",
        "  - Medium model: Use a moderate number of features for a balance between performance and complexity (10 features)\n",
        "  - Large model: Use a comprehensive set of features for maximum discriminative power (20 features).\n",
        "\n",
        "Analyze these models and determine the best of the three."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pMv2QNp53Qp"
      },
      "outputs": [],
      "source": [
        "### Begin your work here. Add as many code or text cells as you deem necessary.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ehNdFvY51Ht"
      },
      "source": [
        "### 3.5 Model Tuning\n",
        "3.5.1. Further partition your training data to validate the optimal value of `k` for each model size (small, medium, large). This step involves creating a validation set from your existing training data to fine-tune the parameter `k` without using your test set.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05Z5irm06C5N"
      },
      "outputs": [],
      "source": [
        "### Begin your work here. Add as many code or text cells as you deem necessary.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9qKljA76Jhn"
      },
      "source": [
        "### 4.  Final Steps\n",
        "After building and comparing various models and tuning the k parameter across different complexities, you are well-equipped to craft a compelling story. Prepare a final presentation that outlines your journey through the data science cycle, the decisions you made, the models you compared, and the insights you gained (ex. patterns in the mistakes the different classifiers made, the improvement from your first classifier to subsequent ones, etc.)\n",
        "\n",
        "This presentation should not only showcase your technical accomplishments but also your ability to convey complex information in an accessible and engaging manner.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKvDcPYUJ4RE"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWx0So3dJ3CZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPNrTNu8BSyc"
      },
      "source": [
        "## 5. Other Classification Methods (OPTIONAL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLvjbXyPBSyc"
      },
      "source": [
        "**Note**: Everything below is **OPTIONAL**. Please only work on this part after you have finished and submitted the project. If you create new cells below, do NOT reassign variables defined in previous parts of the project.\n",
        "\n",
        "Now that you've finished your k-NN classifier, you might be wondering what else you could do to improve your accuracy on the test set. Classification is one of many machine learning tasks, and there are plenty of other classification algorithms! If you feel so inclined, we encourage you to try any methods you feel might help improve your classifier.\n",
        "\n",
        "We've compiled a list of blog posts with some more information about classification and machine learning. Create as many cells as you'd like below--you can use them to import new modules or implement new algorithms.\n",
        "\n",
        "Blog posts:\n",
        "\n",
        "* [Classification algorithms/methods](https://medium.com/@sifium/machine-learning-types-of-classification-9497bd4f2e14)\n",
        "* [Train/test split and cross-validation](https://towardsdatascience.com/train-test-split-and-cross-validation-in-python-80b61beca4b6)\n",
        "* [More information about k-nearest neighbors](https://medium.com/@adi.bronshtein/a-quick-introduction-to-k-nearest-neighbors-algorithm-62214cea29c7)\n",
        "* [Overfitting](https://elitedatascience.com/overfitting-in-machine-learning)\n",
        "\n",
        "In future data science classes, such as Data Science 100, you'll learn about some about some of the algorithms in the blog posts above, including logistic regression. You'll also learn more about overfitting, cross-validation, and approaches to different kinds of machine learning problems.\n",
        "\n",
        "There's a lot to think about, so we encourage you to find more information on your own!\n",
        "\n",
        "Modules to think about using:\n",
        "\n",
        "* [Scikit-learn tutorial](http://scikit-learn.org/stable/tutorial/basic/tutorial.html)\n",
        "* [TensorFlow information](https://www.tensorflow.org/tutorials/)\n",
        "\n",
        "...and many more!"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Edit Metadata",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
